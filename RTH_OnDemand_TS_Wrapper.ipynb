{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0de11408-d92e-46ec-9412-1677af3f3f23",
   "metadata": {},
   "source": [
    "## Tick History Request- Parameterize and Parallelize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5626a515-b051-4f46-84d9-9ca1d462e465",
   "metadata": {},
   "source": [
    " Based on \"RTH Python Code Samples\":\n",
    " <br>\n",
    " https://developers.refinitiv.com/en/api-catalog/refinitiv-tick-history/refinitiv-tick-history-rth-rest-api/download\n",
    " <br>\n",
    " \n",
    "### Introduction to the Approach:\n",
    " * Authentication- token request\n",
    " * Parametrize request (TickHistoryTimeAndSalesRequest)\n",
    " * On Demand extraction request\n",
    " * Extraction status polling request\n",
    " * Extraction notes retrieval\n",
    " *  Send On-demand Extraction Request - parallelize\n",
    " * Data retrieval and save to disk (the data file is gzipped)\n",
    "   <br>\n",
    "   Includes AWS download capability\n",
    " * Data retrieval and save to disk - parallize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9024cbdf-0378-4a49-b5e3-23f2553d931d",
   "metadata": {},
   "source": [
    "### Import Required Modules and Define Required Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b450462d-1047-4aeb-9e83-176d0154a744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import shutil\n",
    "import time\n",
    "import urllib3\n",
    "import gzip\n",
    "import copy\n",
    "import asyncio\n",
    "\n",
    "reqStart = \"https://selectapi.datascope\"  #endpoint URL start\n",
    "\n",
    "requestTSBodyStarter={      #to be parametrized with instruments and date range\n",
    "    \"ExtractionRequest\": {\n",
    "    \"@odata.type\": \"#DataScope.Select.Api.Extractions.ExtractionRequests.TickHistoryTimeAndSalesExtractionRequest\",\n",
    "    \"ContentFieldNames\": [\n",
    "        \"Trade - Exchange/Contributor ID\",\n",
    "        \"Trade - Price\",\n",
    "        \"Trade - Volume\",\n",
    "        \"Trade - Qualifiers\",\n",
    "        \"Trade - Sequence Number\",\n",
    "        \"Trade - Exchange Time\",\n",
    "        \"Trade - Open\",\n",
    "        \"Trade - High\",\n",
    "        \"Trade - Low\",\n",
    "        \"Quote - Bid Price\",\n",
    "        \"Quote - Bid Size\",\n",
    "        \"Quote - Ask Price\",\n",
    "        \"Quote - Ask Size\"\n",
    "    ],\n",
    "    \"IdentifierList\": {\n",
    "    \"@odata.type\": \"#DataScope.Select.Api.Extractions.ExtractionRequests.InstrumentIdentifierList\",  \n",
    "    \"InstrumentIdentifiers\": [\n",
    "    { \"Identifier\": \"CARR.PA\", \"IdentifierType\": \"Ric\" }  #placeholder\n",
    "    ],\n",
    "    \"ValidationOptions\": {\n",
    "        \"AllowHistoricalInstruments\": \"true\"\n",
    "    },\n",
    "    \"UseUserPreferencesForValidationOptions\": \"false\"\n",
    "    },\n",
    "    \"Condition\": {\n",
    "        \"MessageTimeStampIn\": \"GmtUtc\",\n",
    "        \"ApplyCorrectionsAndCancellations\": \"true\",\n",
    "        \"ReportDateRangeType\": \"Range\",\n",
    "        \"QueryStartDate\": \"2021-08-04T00:00:00.000\",  #placeholder\n",
    "        \"QueryEndDate\": \"2021-08-04T23:59:59.999\",    #placeholder\n",
    "        \"DateRangeTimeZone\" : \"Local Exchange Time Zone\",\n",
    "        \"DisplaySourceRIC\": \"false\"\n",
    "    }\n",
    "    }\n",
    "}\n",
    "\n",
    "filePath = \".\\\\downloads\\\\\"  #Location to save downloaded files\n",
    "fileNameRoot = \"RTH.\"     #Root of the name for the downloaded files\n",
    "useAws = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6ef3bd-af44-4fa2-80f4-9ea81ad95ef0",
   "metadata": {},
   "source": [
    "###  Read Credentials from File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b0ec9d-1fd1-4fa6-b221-bd69082ea03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "myUsername = \"Valid\"\n",
    "myPassword = \"ValidOnly\"\n",
    "\n",
    "# comment out the next lines, if the creds are hard-coded instead\n",
    "def readCredsFromFile(filePathName):\n",
    "    global myUsername, myPassword\n",
    "    credFile = open(filePathName,\"r\")    # one per line\n",
    "                                               \n",
    "    myUsername = credFile.readline().rstrip('\\n')\n",
    "    myPassword = credFile.readline().rstrip('\\n')\n",
    "\n",
    "    credFile.close()\n",
    "\n",
    "readCredsFromFile(\"..\\creds\\credsDSS.txt\")\n",
    "#print(myUsername)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64358de0-e086-4ee2-86c1-46bc0d7714ae",
   "metadata": {},
   "source": [
    "### Authentication - Datascope Token Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ced969-842a-43f6-a63d-7c35d0f048d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def requestToken(dssUsername, dssRassword) :\n",
    "    requestUrl = reqStart + \".refinitiv.com/RestApi/v1/Authentication/RequestToken\"\n",
    "\n",
    "    requestHeaders={\n",
    "        \"Prefer\":\"respond-async\",\n",
    "        \"Content-Type\":\"application/json\"\n",
    "        }\n",
    "\n",
    "    requestBody={\n",
    "        \"Credentials\": {\n",
    "        \"Username\": myUsername,\n",
    "        \"Password\": myPassword\n",
    "    }\n",
    "    }\n",
    "\n",
    "    r1 = requests.post(requestUrl, json=requestBody,headers=requestHeaders)\n",
    "\n",
    "    if r1.status_code == 200 :\n",
    "        jsonResponse = json.loads(r1.text.encode('ascii', 'ignore'))\n",
    "        token = jsonResponse[\"value\"]\n",
    "   #     print ('Authentication token (valid 24 hours):')\n",
    "   #     print (token)\n",
    "    else:\n",
    "        print ('Replace myUserName and myPassword with valid credentials, then repeat the request')\n",
    "        token = 'None'\n",
    "    \n",
    "    return token\n",
    "\n",
    "tokenValid = requestToken(myUsername, myPassword)\n",
    "print(\"Authentication token (valid 24 hours): \"+tokenValid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e0faf0-52a4-49b8-be1d-8e078da56b90",
   "metadata": {},
   "source": [
    "### Parametrise Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8474098-0552-4a89-8d47-60fd79d560be",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  RICs (instruments) and date ranges for request parametrization\n",
    "request1Parameters = {\n",
    "    \"RICs\": [\"CARP.PA\",\"IBM.N\",\"MSFT.O\",\"VOD.L\"],\n",
    "    \"QueryStartDate\": \"2022-01-04T00:00:00.000\",\n",
    "    \"QueryEndDate\": \"2022-01-04T03:59:59.999\"\n",
    "}\n",
    "\n",
    "request2Parameters = {\n",
    "    \"RICs\": [\"JPY=\",\"EUR=\",\"U30YT=RR\"],\n",
    "    \"QueryStartDate\": \"2021-01-04T00:00:00.000\",\n",
    "    \"QueryEndDate\": \"2021-01-04T03:59:59.999\"\n",
    "}\n",
    "\n",
    "def paramterizeRequest(requestBodyStarter, requestParameters):\n",
    "    requestBody = copy.deepcopy(requestBodyStarter)\n",
    "    i = 0\n",
    "    for i, ric in enumerate(requestParameters[\"RICs\"]):\n",
    "#        print(i, ric)\n",
    "        if i == 0:\n",
    "            requestBody[\"ExtractionRequest\"][\"IdentifierList\"][\"InstrumentIdentifiers\"][i][\"Identifier\"] = ric\n",
    "            requestBody[\"ExtractionRequest\"][\"IdentifierList\"][\"InstrumentIdentifiers\"][i][\"IdentifierType\"] = \"Ric\"\n",
    "        else:\n",
    "            requestBody[\"ExtractionRequest\"][\"IdentifierList\"][\"InstrumentIdentifiers\"].append({ \n",
    "                'Identifier' : ric, \n",
    "                'IdentifierType' : 'Ric'}) \n",
    "    requestBody[\"ExtractionRequest\"][\"Condition\"][\"QueryStartDate\"] = requestParameters[\"QueryStartDate\"]\n",
    "    requestBody[\"ExtractionRequest\"][\"Condition\"][\"QueryEndDate\"] = requestParameters[\"QueryEndDate\"]\n",
    "\n",
    "    return requestBody\n",
    " \n",
    "request1Body = paramterizeRequest(requestTSBodyStarter, request1Parameters)\n",
    "print(\"requestBody ready to submit: \\n\"+json.dumps(request1Body, indent = 2))\n",
    "request2Body = paramterizeRequest(requestTSBodyStarter, request2Parameters)\n",
    "print(\"requestBody ready to submit: \\n\"+json.dumps(request2Body, indent = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06666e64-c169-4647-be30-6c5c7b1f9494",
   "metadata": {},
   "source": [
    "### Send On-demand Extraction Request - Define\n",
    "send an on demand extraction request using the received token "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e515772c-1319-4639-af82-f85c267c354b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "async def submitRequest(token, requestBody, requestMarker):\n",
    "\n",
    "    requestUrl=reqStart + '.refinitiv.com/RestApi/v1/Extractions/ExtractRaw'\n",
    "\n",
    "    requestHeaders={\n",
    "        \"Prefer\":\"respond-async\",\n",
    "        \"Content-Type\":\"application/json\",\n",
    "        \"Authorization\": \"token \" + token\n",
    "    }\n",
    "    \n",
    "    loop = asyncio.get_event_loop()\n",
    "\n",
    "    print(\"posting request \"+ json.dumps(requestBody))\n",
    "    requestP = partial(requests.post, requestUrl, json=requestBody,headers=requestHeaders)\n",
    "    r2 = await loop.run_in_executor(None, requestP)\n",
    "\n",
    "    #Display the HTTP status of the response\n",
    "    #Initial response status (after approximately 30 seconds wait) is usually 202\n",
    "    status_code = r2.status_code\n",
    "    print (requestMarker, \"HTTP status of the response: \" + str(status_code))\n",
    "\n",
    "    #if required, poll the status of the request using the received location URL.\n",
    "    #Once the request has completed, retrieve the jobId and extraction notes.\n",
    "\n",
    "    #If status is 202, display the location url we received, and will use to poll the status of the extraction request:\n",
    "    if status_code == 202 :\n",
    "        requestUrl = r2.headers[\"location\"]\n",
    "        print (requestMarker, 'Extraction is not complete, we shall poll the location URL:')\n",
    "        print (str(requestUrl))\n",
    "        \n",
    "        requestHeaders={\n",
    "            \"Prefer\":\"respond-async\",\n",
    "            \"Content-Type\":\"application/json\",\n",
    "            \"Authorization\":\"token \" + token\n",
    "        }\n",
    "\n",
    "    #As long as the status of the request is 202, the extraction is not finished;\n",
    "    #we must wait, and poll the status until it is no longer 202:\n",
    "    r3 = \"\"\n",
    "    while (status_code == 202):\n",
    "        print (requestMarker,'As we received a 202, we wait 30 seconds, then poll again (until we receive a 200)')\n",
    "        time.sleep(30)\n",
    "        requestG = partial(requests.get, requestUrl,headers=requestHeaders)\n",
    "        r3 = await loop.run_in_executor(None, requestG)\n",
    "        status_code = r3.status_code\n",
    "        print (requestMarker, 'HTTP status of the response: ' + str(status_code))\n",
    "\n",
    "    if r3 == \"\":\n",
    "        r3 = r2\n",
    "    #When the status of the request is 200 the extraction is complete;\n",
    "    #we retrieve and display the jobId and the extraction notes (it is recommended to analyse their content)):\n",
    "    if status_code == 200 :\n",
    "        r3Json = json.loads(r3.text.encode('ascii', 'ignore'))\n",
    "        jobId = r3Json[\"JobId\"]\n",
    "        print ('\\njobId: ' + jobId + '\\n')\n",
    "        notes = r3Json[\"Notes\"]\n",
    "        print (requestMarker, 'Extraction notes:\\n' + notes[0])\n",
    "\n",
    "    #If instead of a status 200 we receive a different status, there was an error:\n",
    "    if status_code != 200 :\n",
    "        jobId = -1\n",
    "        print (requestMarker, 'An error occurred.\\n')\n",
    "    \n",
    "    return jobId\n",
    "\n",
    "#job1Id = submitRequest(tokenValid, request1Body)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd56e505-db9f-4481-863f-9bdb3bcc52e2",
   "metadata": {},
   "source": [
    "### Send On-demand Extraction Request - Parallelize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04130989-ec11-40e5-905a-32d62fc7c135",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tasks = asyncio.gather(\n",
    "    submitRequest(tokenValid, request1Body, 'request#1'),\n",
    "    submitRequest(tokenValid, request2Body, 'request#2')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04a47f0-bc8f-4f50-83d0-9e6e371531d6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#asyncio.get_event_loop().run_until_complete(tasks)\n",
    "print(await tasks)\n",
    "job1Id, job2Id = tasks.result()\n",
    "print(job1Id,job2Id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb96b222-54ff-4bce-beef-818e8dee3c1c",
   "metadata": {},
   "source": [
    "### Retrieve Results and Save to File - Define\n",
    "* Get the extraction results, using the received jobId.\n",
    "* We also save the compressed data to disk, as a GZIP.\n",
    "* We only display a few lines of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d14d7a0-db3e-4622-8ec7-a23bbfd76964",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def retrieveResults(token, jobId, resultMarker):\n",
    "    requestUrl = reqStart + \".refinitiv.com/RestApi/v1/Extractions/RawExtractionResults\" + \"('\" + jobId + \"')\" + \"/$value\"\n",
    "\n",
    "    #AWS requires an additional header: X-Direct-Download\n",
    "    if useAws:\n",
    "        requestHeaders={\n",
    "            \"Prefer\":\"respond-async\",\n",
    "            \"Content-Type\":\"text/plain\",\n",
    "            \"Accept-Encoding\":\"gzip\",\n",
    "            \"X-Direct-Download\":\"true\",\n",
    "            \"Authorization\": \"token \" + token\n",
    "        }\n",
    "    else:\n",
    "        requestHeaders={\n",
    "            \"Prefer\":\"respond-async\",\n",
    "            \"Content-Type\":\"text/plain\",\n",
    "            \"Accept-Encoding\":\"gzip\",\n",
    "            \"Authorization\": \"token \" + token\n",
    "        }\n",
    "\n",
    "    r5 = requests.get(requestUrl,headers=requestHeaders,stream=True)\n",
    "    #Ensure we do not automatically decompress the data on the fly:\n",
    "    r5.raw.decode_content = False\n",
    "    if useAws:\n",
    "        print ('Content response headers (AWS server): type: ' + r5.headers[\"Content-Type\"] + '\\n')\n",
    "        #AWS does not set header Content-Encoding=\"gzip\".\n",
    "    else:\n",
    "        print ('Content response headers (TRTH server): type: ' + r5.headers[\"Content-Type\"] + ' - encoding: ' + r5.headers[\"Content-Encoding\"] + '\\n')\n",
    "    \n",
    "    fileName = filePath + fileNameRoot + resultMarker +\".csv.gz\"\n",
    "    print (resultMarker, 'Saving compressed data to file:' + fileName + ' ... please be patient')\n",
    "   \n",
    "    chunk_size = 1024\n",
    "    rr = r5.raw\n",
    "    with open(fileName, 'wb') as fd:\n",
    "        shutil.copyfileobj(rr, fd, chunk_size)\n",
    "    fd.close\n",
    "\n",
    "    print ('Finished saving compressed data to file:' + fileName + '\\n')\n",
    "\n",
    "    #Now let us read and decompress the file we just created.\n",
    "    #For the demo we limit the treatment to a few lines:\n",
    "    maxLines = 10\n",
    "    print ('Read data from file, and decompress at most ' + str(maxLines) + ' lines of it:')\n",
    "\n",
    "    uncompressedData = \"\"\n",
    "    count = 0\n",
    "    with gzip.open(fileName, 'rb') as fd:\n",
    "        for line in fd:\n",
    "            dataLine = line.decode(\"utf-8\")\n",
    "            #Do something with the data:\n",
    "            print (dataLine)\n",
    "            uncompressedData = uncompressedData + dataLine\n",
    "            count += 1\n",
    "            if count >= maxLines:\n",
    "                break\n",
    "    fd.close()\n",
    "    \n",
    "#retrieveResults(tokenValid, job1Id, 'result1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d66d070-860c-4c06-ad8d-4255cd88e85e",
   "metadata": {},
   "source": [
    "### Retrieve Results and Save to File - Prallelize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf9157b-ae72-455c-a590-68dc7e8ab0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = asyncio.gather(\n",
    "    retrieveResults(tokenValid, job1Id, 'result#1'),\n",
    "    retrieveResults(tokenValid, job2Id, 'result#2')\n",
    ")\n",
    "#asyncio.get_event_loop().run_until_complete(tasks)\n",
    "print(await tasks)\n",
    "print(\"<<<All done>>>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b47bf34-5127-44d8-8532-3dcb5ea9d5fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
